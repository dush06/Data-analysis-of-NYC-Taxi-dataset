---
title: "Practicum 3"
author: "Dushyanth Gopichand"
date: "8/10/2021"
output: html_document
---

Installing and loading all useful libraries

```{r}
#install.packages("caret")
#install.packages("class")
#install.packages("questionr")
#install.packages("FNN")
library(tidyverse)
library(ggplot2)
library(caret)
library(class)
library(psych)
library(dplyr)
library(lubridate)
library(questionr)
library(FNN)
```

Question 1 —(20 points) +10 optional points CRISP-DM: Data Understanding  •Loadthe NYC Green Taxi Trip Recordsdata directly from the URLinto a data frame or tibble. 

```{r}
#Loading data into a dataframe
NYC_taxi <- read.csv("https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2020-02.csv", header = TRUE)

```

Data exploration:explore the data to identify any patterns and analyze the relationships between the features and the target variable i.e. tip amount.  1) the distribution, 2)  the correlations 3) missing values and 4) outliers 

```{r}

#Viewing the data
head(NYC_taxi)
str(NYC_taxi)
summary(NYC_taxi)
colnames(NYC_taxi)

# 1) Distribution

#Convert store_and_fwd_flag to numeric for distribution and correlation
NYC_taxi$store_and_fwd_flag <- ifelse(NYC_taxi$store_and_fwd_flag== "Y", 0, 1)

#Clean the data for lpep_pickup_datetime and lpep_dropoff_datetime for distribution and correlation
NYC_taxi$lpep_pickup_datetime <-  ymd_hms(NYC_taxi$lpep_pickup_datetime,tz=Sys.timezone())
NYC_taxi$lpep_dropoff_datetime <-  ymd_hms(NYC_taxi$lpep_dropoff_datetime,tz=Sys.timezone())

NYC_taxi <- NYC_taxi %>%
mutate (pickup.date = (mday(lpep_dropoff_datetime))) %>%
  mutate(pickup.month = month(lpep_dropoff_datetime)) %>%
  mutate(pickup.hour= hour(lpep_dropoff_datetime)) %>%
  mutate (drop.date = (mday(lpep_dropoff_datetime))) %>%
  mutate(drop.month = month(lpep_dropoff_datetime)) %>%
  mutate(drop.hour= hour(lpep_dropoff_datetime))

#Only extracted date, month and hour from lpep_pickup_datetime and lpep_dropoff_datetime since the year is common to all and hours and seconds might not create a major difference
head(NYC_taxi)

#Creating histograms for distribution

#Creating histograms for distribution

hist(NYC_taxi$VendorID,main = 'Distribution of VendorID',xlab='VendorID',ylab ='frequency')
hist(NYC_taxi$store_and_fwd_flag,main = 'Distribution of Store and forward flag',xlab='Store and forward flag',ylab ='frequency')
hist(NYC_taxi$RatecodeID, main = 'Distribution of Rate code ID',xlab='Rate code ID',ylab ='frequency')
hist(NYC_taxi$PULocationID, main = 'Distribution of PULocation ID',xlab='PULocationID',ylab ='frequency')
hist(NYC_taxi$DOLocationID, main = 'Distribution of DOLocation ID',xlab='DOLocationID',ylab ='frequency')
hist(NYC_taxi$passenger_count, main = 'Distribution of the Passenger Count',xlab='Passenger Count',ylab ='frequency')
hist(NYC_taxi$trip_distance,main = 'Distribution of the Passenger Count', xlab='Trip Distance',ylab ='frequency')
hist(NYC_taxi$fare_amount, main = 'Distribution of the fare amount', xlab='Fare Amount', ylab ='frequency')
hist(NYC_taxi$extra, main = 'Distribution of the extra charges', xlab='Extra Charges', ylab ='frequency')
hist(NYC_taxi$mta_tax, main = 'Distribution of the MTA tax', xlab='MTA Tax', ylab ='frequency')
hist(NYC_taxi$tip_amount, main = 'Distribution of the tip amount', xlab='Tip Amount', ylab ='frequency')
hist(NYC_taxi$tolls_amount, main = 'Distribution of the tolls amount', xlab='Toll Amount', ylab ='frequency')
hist(NYC_taxi$improvement_surcharge, main = 'Distribution of the tolls amount', xlab='Toll Amount', ylab ='frequency')
hist(NYC_taxi$payment_type, main = 'Distribution of the Payment Type', xlab='Payment Type', ylab ='frequency')
hist(NYC_taxi$trip_type, main = 'Distribution of the trip type', xlab='Trip Type', ylab ='frequency')
hist(NYC_taxi$congestion_surcharge, main = 'Distribution of the Congestion Surcharge', xlab='Congestion Surcharge', ylab ='frequency')
```

**Comments- VendorID- The graph is not a normal distribution as there are only 2 categories and Vendor ID 2 has higher frequency**
**store_and_fwd_flag- The graph is not a normal distribution as there are only 2 categories and store_and_fwd_flag 1 has higher frequency**
**RatecodeID-  Not a normal distribution but most distributions are towards the left so it is right skewed**
**PULocationID and DOlocationID- multimodal distribution but skewed towards right**
**passenger_count, trip_distance, fare_amount, extra, tip_amount, tolls_amount and congestion surcharge - Right skewed distribution**
**mta_tax,improvement_surcharge - left skewed distribution**
**payment_type is a categorical variable too and higher frequency for type 1 and 2**
**trip_type is a categorical variable too and higher frequency for type 1** 


```{r}
#2) Corelation

cor_model <- cor(NYC_taxi[c("VendorID", "pickup.date", "pickup.month",  "pickup.hour", "drop.date", "drop.month", "drop.hour", "store_and_fwd_flag", "RatecodeID", "PULocationID", "DOLocationID", "passenger_count", "trip_distance", "fare_amount", "extra", "mta_tax", "tip_amount", "tolls_amount", "ehail_fee", "improvement_surcharge", "total_amount", "payment_type", "trip_type", "congestion_surcharge")])
cor_model
#Using everything
corr.m <- cor(NYC_taxi[c("VendorID", "pickup.date", "pickup.month",  "pickup.hour", "drop.date", "drop.month", "drop.hour", "store_and_fwd_flag", "RatecodeID", "PULocationID", "DOLocationID", "passenger_count", "trip_distance", "fare_amount", "extra", "mta_tax", "tip_amount", "tolls_amount", "ehail_fee", "improvement_surcharge", "total_amount", "payment_type", "trip_type", "congestion_surcharge")], use= "everything")
corr.m
#Using pairwise
corr.pairwise <- cor(NYC_taxi[c("VendorID", "pickup.date", "pickup.month",  "pickup.hour", "drop.date", "drop.month", "drop.hour", "store_and_fwd_flag", "RatecodeID", "PULocationID", "DOLocationID", "passenger_count", "trip_distance", "fare_amount", "extra", "mta_tax", "tip_amount", "tolls_amount", "ehail_fee", "improvement_surcharge", "total_amount", "payment_type", "trip_type", "congestion_surcharge")], use= "pairwise.complete.obs")
corr.pairwise
```

**Comments- when we select the columns as it is, a number of correlations show NA due to missing values in the data frame. When we select use= everything in corr.m, there is an improvement as NAs will propagate conceptually, i.e., a resulting value will be NA whenever one of its contributing observations is NA. Multicollinearity - pick up month and drop month, pickup date & dropdate, pick up hour & drop hour present multicollinearity so we can remove one from each pair.Other columns with very low correlation are pickup.date, pickup.month,  PULocationID, DOLocationID, passenger_count. If we consider corr.pairwise, trip distance has a low correlation**

```{r}
# 3) Missing value

freq.na(NYC_taxi)

# 4) Outliers
boxplot(NYC_taxi$passenger_count,main = 'Outliers in the Passenger Count',xlab='Passenger Count',ylab = 'Number of Outliers', sub = 'Visualization of Outliers')
boxplot(NYC_taxi$trip_distance,main = 'Outliers in Trip Distance', xlab='Trip Distance',ylab = 'Number of Outliers',sub = 'Visualization of Outliers')
boxplot(NYC_taxi$fare_amount,main = 'Outliers in Fare amount', xlab='Fare amount',ylab = 'Number of Outliers',sub = 'Visualization of Outliers' )
boxplot(NYC_taxi$extra, main = 'Outliers in Extra charges', xlab='Extra',ylab = 'Number of Outliers',sub = 'Visualization of Outliers')
boxplot(NYC_taxi$mta_tax, main = 'Outliers in MTA TAx', xlab='MTA Tax',ylab = 'Number of Outliers',sub = 'Visualization of Outliers')
boxplot(NYC_taxi$tip_amount, main = 'Outliers in Tip Amount', xlab='Tip Amount',ylab = 'Number of Outliers',sub = 'Visualization of Outliers')
boxplot(NYC_taxi$tolls_amount, main = 'Outliers in Tolls Amount', xlab='Tolls Amount',ylab = 'Number of Outliers',sub = 'Visualization of Outliers')
boxplot(NYC_taxi$improvement_surcharge,main = 'Outliers in improvement surcharge', xlab='Improvement surcharge',ylab = 'Number of Outliers',sub = 'Visualization of Outliers' )
boxplot(NYC_taxi$total_amount,main = 'Outliers in Total Amount', xlab='Total Amount',ylab = 'Number of Outliers',sub = 'Visualization of Outliers')
```
**Comments- 20% of the values are missing in a few columns and the ehail fee column is completely empty. On careful observation a number of rows (~80,000) have more than one column as NA. The outliers are shown using boxplots**

```{r}

# Feature selection: selecting features based on p values

model <- lm(tip_amount ~ VendorID+ pickup.date+ pickup.month+ pickup.hour+ drop.date+ drop.month+ drop.hour+ store_and_fwd_flag+ RatecodeID+ PULocationID+ DOLocationID+ passenger_count+ trip_distance+ fare_amount+ extra+ mta_tax+ tolls_amount+ improvement_surcharge+ total_amount+ payment_type+ trip_type+ congestion_surcharge, data = NYC_taxi )
summary(model)

#Removing non-significant columns drop.date, drop.month, drop.hour as they have a higher p value
model1 <- lm(tip_amount ~ VendorID+ pickup.date+ pickup.month+ pickup.hour+ store_and_fwd_flag+ RatecodeID+ PULocationID+ DOLocationID+ passenger_count+ trip_distance+ fare_amount+ extra+ mta_tax+ tolls_amount+ improvement_surcharge+ total_amount+ payment_type+ trip_type+ congestion_surcharge, data = NYC_taxi)
summary(model1) # No change in adjusted R value

#Removing non-significant columns trip_distance and PULocationID as they have a higher p value
model2 <- lm(tip_amount ~ VendorID+ pickup.date+ pickup.month+ pickup.hour+ store_and_fwd_flag+ RatecodeID+ DOLocationID+ passenger_count+ fare_amount+ extra+ mta_tax+ tolls_amount+ improvement_surcharge+ total_amount+ payment_type+ trip_type+ congestion_surcharge, data = NYC_taxi)
summary(model2) # No change in adjusted R value

#Removing non-significant columns DOLocationID and store_and_fwd_flag as they have a higher p value
model3 <- lm(tip_amount ~ VendorID+ pickup.date+ pickup.month+ pickup.hour+ RatecodeID+ passenger_count+ fare_amount+ extra+ mta_tax+ tolls_amount+ improvement_surcharge+ total_amount+ payment_type+ trip_type+ congestion_surcharge, data = NYC_taxi)
summary(model3) # No change in adjusted R value

#Removing non-significant columns RatecodeID and passenger_count as they have a higher p value
model4 <- lm(tip_amount ~ VendorID+ pickup.date+ pickup.month+ pickup.hour+ fare_amount+ extra+ mta_tax+ tolls_amount+ improvement_surcharge+ total_amount+ payment_type+ trip_type+ congestion_surcharge, data = NYC_taxi)
summary(model4) # No change in adjusted R value
```

**The feature selection from the final model includes the following variables: VendorID, pickup.date, pickup.month, pickup.hour, fare_amount, extra, mta_tax, tolls_amount, improvement_surcharge, total_amount, payment_type, trip_type and congestion_surcharge **

```{r}
#Feature engineering- The idea is to create a new feature to divide the days into Weekdays (Mon:Thu) and weekends(Fri:Sunday). We have selected Friday in weekend since it is the last day of weekdays and begining of the week and majority of trips have been on Fridays too.

NYC_taxi <- NYC_taxi %>%
  mutate(pickup.week= wday(lpep_pickup_datetime, label = TRUE))

NYC_taxi$pickup.week <- ifelse(NYC_taxi$pickup.week %in% c("Mon", "Tue", "Wed", "Thu"), 0, 1)
NYC_taxi %>% count(pickup.week)

#Line graph
ggplot(data= NYC_taxi, aes(x= pickup.week, y= tip_amount)) + geom_line() + labs(title = 'Feature engineering of Pickup Weekdays and Weekends', x = 'Pickup Week', y = 'Tip Amount', caption = 'Visualization of Feature Engineering')

#It can be clearly seen that there is a big difference in tip amount for weekends than weekdays and this might affect prediction. Thus the new variable is worth considering

#2nd feature engineering: The pick up hour column has been engineered into morning and evening. Time between 6 hours to 17 hours has been considered morning with a code of 0 and hours 18 to 23 are coded 1 depicting night 

NYC_taxi %>% count(pickup.hour)

NYC_taxi$pickup.hour <- ifelse(NYC_taxi$pickup.hour %in% c("18", "19", "20", "21", "22", "23", "0", "1", "2", "3", "4", "5"), 1, 0)

ggplot(data= NYC_taxi, aes(x= pickup.hour, y= tip_amount)) + geom_line() + labs(title = 'Feature engineering of Pickup Hour', x = 'Pickup Hour', y = 'Tip Amount', caption = 'Visualization of Feature Engineering')

#Since the line graph shows tips to be more for code 0, i.e. morning time, we will include this in the final features
```
**Final features selected: VendorID, pickup.date, pickup.month, pickup.hour, fare_amount, extra, mta_tax, tolls_amount, improvement_surcharge, total_amount, payment_type, trip_type, congestion_surcharge. We also selected pickup.week and pickup.hour from feature engineering. Some changes: It was seen from the correlation that pick up date and month have very low correlation. Moreover, the pick up month is February throughout, so it cannot be a useful parameter for prediction. Moreover, pickup date are also dates of only February and they will not be a good variable foe future selections.**

**Thus, our final features are as follows: VendorID, fare_amount, extra, mta_tax, tolls_amount, improvement_surcharge, total_amount, payment_type, trip_type, congestion_surcharge, pickup week and pickup hour**

Question 2 
**Preprocess the data: handle missing data and outliers, perform any suitable data transformation steps, etc. Also, ensure that you filter the data. The goal is to predict the tip amount, therefore you need to ensure that you extract the data that contains this information**
```{r}
#  handle missing data

#Removing the ehail_fee column as it is empty
NYC_taxi <- NYC_taxi[ , -15]

#Since the variable comp has all complete cases and the ~80,000 rows have multiple missing rows, they can be removed.
NYC_taxi <- NYC_taxi[complete.cases(NYC_taxi), ] #All rows that are incomplete
# Removing Outliers
o1 <- boxplot(NYC_taxi$passenger_count,plot=FALSE)$out
o2 <- boxplot(NYC_taxi$trip_distance,plot=FALSE)$out
o3 <- boxplot(NYC_taxi$fare_amount,plot=FALSE)$out
o4 <- boxplot(NYC_taxi$extra,plot=FALSE)$out
o5 <- boxplot(NYC_taxi$mta_tax,plot=FALSE)$out
o6 <- boxplot(NYC_taxi$tip_amount,plot=FALSE)$out
o7 <- boxplot(NYC_taxi$tolls_amount,plot=FALSE)$out
o8 <- boxplot(NYC_taxi$improvement_surcharge,plot=FALSE)$out
o9 <- boxplot(NYC_taxi$total_amount,plot=FALSE)$out
# Removing outliers
NYC_taxi <- NYC_taxi[-which(NYC_taxi$passenger_count %in% o1),]
NYC_taxi <- NYC_taxi[-which(NYC_taxi$trip_distance %in% o2),]
NYC_taxi <- NYC_taxi[-which(NYC_taxi$fare_amount %in% o3),]
NYC_taxi <- NYC_taxi[-which(NYC_taxi$extra %in% o4),]
NYC_taxi <- NYC_taxi[-which(NYC_taxi$mta_tax %in% o5),]
NYC_taxi <- NYC_taxi[-which(NYC_taxi$tip_amount %in% o6),]
NYC_taxi <- NYC_taxi[-which(NYC_taxi$tolls_amount %in% o7),]
NYC_taxi <- NYC_taxi[-which(NYC_taxi$improvement_surcharge %in% o8),]
NYC_taxi <- NYC_taxi[-which(NYC_taxi$total_amount %in% o9),]
head(NYC_taxi)

#Data transformation. A few transformation steps were done in Q1

#Filter data. We will first filter out data only for the month of Feb since that is the objective and then We will select only the variables we selected in the feature selection phase

NYC_taxi <- NYC_taxi %>% filter(pickup.month== "2")

NYC_taxi_df <- NYC_taxi %>% select(VendorID, pickup.hour, fare_amount, extra, mta_tax, tip_amount, tolls_amount, improvement_surcharge, total_amount, payment_type, trip_type, congestion_surcharge, pickup.week)

```

**Normalize the data**
```{r}
#Min max normalization
nor1 <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}

# Min max normalization to normalize the constant columns 
nor2 <- function(x) {
   return(ifelse(min(x) < max(x), (x - min(x)) / (max(x) - min(x)),x))
 }


NYC_taxi_df$fare_amount <- nor1(NYC_taxi_df$fare_amount) 
NYC_taxi_df$extra <- nor1(NYC_taxi_df$extra)
NYC_taxi_df$total_amount <- nor1(NYC_taxi_df$total_amount)
NYC_taxi_df$congestion_surcharge <- nor1(NYC_taxi_df$congestion_surcharge)

# Normalizing the constant columns 
NYC_taxi_df$mta_tax <- nor2(NYC_taxi_df$mta_tax)
NYC_taxi_df$tolls_amount <- nor2(NYC_taxi_df$tolls_amount) 
NYC_taxi_df$improvement_surcharge <- nor2(NYC_taxi_df$improvement_surcharge)


head(NYC_taxi_df)
```
**Encode the data- the categorical variables (payment_type, trip_type) are already encoded.**
```{r}

#VendorID change to 0 and 1

NYC_taxi_df$VendorID <- ifelse(NYC_taxi_df$VendorID== "1", 0, 1)

#trip_type change to 0 and 1
NYC_taxi_df$trip_type <- ifelse(NYC_taxi_df$trip_type== "1", 0, 1)

summary(NYC_taxi_df)

#Dummy coding for payment type

payment_type <- as.data.frame(dummy.code(NYC_taxi_df$payment_type))
payment_type <- rename(payment_type,p1 = 1, p2 = 2, p3 = 3, p4 = 4, p5 = 5)

# Combine new dummy variables with original data set.
NYC_taxi_df <- cbind(NYC_taxi_df, payment_type)

# Remove original variables that had to be dummy coded.
NYC_taxi_df <- NYC_taxi_df %>% select(-one_of("payment_type"))

```

**Prepare the data for modeling- making an 80-20 split following the pareto principal. Also, the training data if taken small, there can be greater variance**
```{r}
set.seed(123)
split <- sort(sample(nrow(NYC_taxi_df), nrow(NYC_taxi_df)*0.8))
data_train_NYCtaxi <- NYC_taxi_df[split,]
dim(data_train_NYCtaxi)
data_test_NYCtaxi <- NYC_taxi_df[-split,]
dim(data_test_NYCtaxi)
tip_train <- NYC_taxi_df[split,6]
tip_test <- NYC_taxi_df[-split,6]
```
Question 3
**In this step you will develop the k-nn regression model. Create a function with the following name and arguments: knn.predict(data_train, data_test, k)**
**Implement the k-nn algorithm and use it to predict the tip amount for each observation in the test set i.e. data_test.**  
**Calculate the mean squared error (MSE) between the predictions from the k-nn model and the actual tip amount in the test set.**
**The knn-predict()function should return the MSE.**
```{r}
 knn.predict <- function(data_train, data_test, k) 
{
    #extract 6th column from the dataset because it will be used as 'cl' argument in knn function.
    NYC_train_tip <- NYC_taxi_df[split,6]
    #extract 6th column from the dataset to measure the MSE
    NYC_test_tip <- NYC_taxi_df[-split,6]
    #run KNN function
    knn_reg_result <- knn.reg(data_train,data_test, NYC_train_tip, k=k)
    #MSE calculation 
    MSE <-mean((NYC_test_tip - knn_reg_result$pred)^2)
    cat("The MSE for k =", k, "is", MSE, '\n')
    return(MSE)
 }
n = nrow(data_train_NYCtaxi)
k_value = round(sqrt(n))
k_value

knn_pred_fun <- knn.predict(data_train_NYCtaxi, data_test_NYCtaxi, 430)
```
**There are many lib function for KNN, but we have decide to use knn.reg() from the library FNN. There are several rules of thumb for selecting an optimal value for k, one being the square root of the number of observations in the training set. In this case, we select 430 as the number of neighbors, which is approximately the square root of our sample size N = 184580.**

Question 4
**Determine the best value of k and visualize the MSE. This step requires selecting different values of k and evaluating which produced the lowest MSE. At a minimum, ensure that you perform the following:**  
**Provide at least 20 different values of k to the knn.predict()function (along with the training set and the test set).  Tip: use a loop! Use a loop to call knn.predict()20 times and in each iteration of the loop, provide a different value of k to knn.predict(). Ensure that you save the MSE that’s returned.** 
**Create a line chart and plot each value of k on the x-axis and the corresponding MSE on the y-axis. Explain the chart and determine which value of k is more suitable and why.**  
**What are your thoughts on the model that you developed and the accuracy of its predictions? Would you advocate for its use to predict the tip amount of future trips? Explain your answer.** 
```{r}
mse_val <- 0

for (i in seq(200, 600, 20)) #declaring initial value of k 
   {
    k_rag <- knn.predict(data_train_NYCtaxi, data_test_NYCtaxi, k=i)
    mse_val[i] <- k_rag 
    k=i
    cat('k =', k, ' and MSR =', mse_val[i],'\n')
   }
plot(mse_val, type = "b",  xlab = "k-value", ylab = "MSE", xlim = c(200,600), ylim = c(0.001, 0.004), main = "Line graph of K-vale vs MSE")

```
```{r}
# Accuracy for K = 200
set.seed(123)
split <- sort(sample(nrow(NYC_taxi_df), nrow(NYC_taxi_df)*0.8))
train <- NYC_taxi_df[split,]

test <- NYC_taxi_df[-split,]

tip_train <- NYC_taxi_df[split,6]
tipTrainf = factor(tip_train)

tip_test <- NYC_taxi_df[-split,6]
tipTestf <- factor(tip_test)


fit1 <-  knn(train, test, tipTrainf, k = 200, prob = TRUE)
cm1 <-  as.matrix(table(Actual = tipTestf, predicted = fit1))

A1 <- sum(diag(cm1)) / length(tipTestf) * 100


```
**We took 20 different k values from 200 to 600 for our model evaluation. We found out for K=200, we get the least MSE(mean Square Error) of 0.00134198 and an accuracy of 55.57%, and K = 600, the MSE was 0.003815521. For 20 different values of K, the accuracy of our model remained the same around 55%, which is low. Our model predicts right tip amount only 55% of the time. In our unanimous opinion, its not a great model, since slightly less than half the time our model predictions are wrong.**
**We would not advocate to use this model for future predictions. Accuracy is slightly above 50%, hence its a game one one play to use this model.**


**Question 5** —(10 optional/bonus points) 
2) optimize the k-nn model and evaluate the effect of the percentage split, between the training and test set, on the MSE. 
Evaluate the effect of the percentage split for the training and test sets and determine if a different split ratio improves your model’s ability to make better predictions. 

```{r}
# 1 Train:67%, Test:33%
set.seed(123)
split1 <- sort(sample(nrow(NYC_taxi_df), nrow(NYC_taxi_df)*0.67))
data_train_NYCtaxi_newsplit1 <- NYC_taxi_df[split1,]
data_test_NYCtaxi_newsplit1 <- NYC_taxi_df[-split1,]
k1 <- round(sqrt(nrow(data_test_NYCtaxi_newsplit1)))
k1
knn.predict1 <- function(data_train, data_test, k) 
{
    #extract 6th column from the dataset because it will be used as 'cl' argument in knn function.
    NYC_train_tip1 <- NYC_taxi_df[split1,6]
    #extract 6th column from the dataset to measure the MSE
    NYC_test_tip1 <- NYC_taxi_df[-split1,6]
    #run KNN function
    knn_reg_result <- knn.reg(data_train,data_test, NYC_train_tip1, k=k1)
    #MSE calculation 
    MSE1 <-mean((NYC_test_tip1 - knn_reg_result$pred)^2)
    cat("The MSE for k =", k, "is", MSE1, '\n')
    return(MSE1)
 }
knn_pred1 <-knn.predict1(data_train_NYCtaxi_newsplit1, data_test_NYCtaxi_newsplit1, 393)
```

```{r}
# 2 Train:70%, Test:30%
set.seed(123)
split2 <- sort(sample(nrow(NYC_taxi_df), nrow(NYC_taxi_df)*0.7))
data_train_NYCtaxi_newsplit2 <- NYC_taxi_df[split2,]
data_test_NYCtaxi_newsplit2<- NYC_taxi_df[-split2,]

k2 <- round(sqrt(nrow(data_train_NYCtaxi_newsplit2)))
k2

knn.predict2 <- function(data_train, data_test, k) 
{
    #extract 6th column from the dataset because it will be used as 'cl' argument in knn function.
    NYC_train_tip2 <- NYC_taxi_df[split2,6]
    #extract 6th column from the dataset to measure the MSE
    NYC_test_tip2 <- NYC_taxi_df[-split2,6]
    #run KNN function
    knn_reg_result <- knn.reg(data_train,data_test, NYC_train_tip2, k=k2)
    #MSE calculation 
    MSE2 <-mean((NYC_test_tip2 - knn_reg_result$pred)^2)
    cat("The MSE for k =", k, "is", MSE2, '\n')
    return(MSE2)
 }
knn_pred2 <- knn.predict2(data_train_NYCtaxi_newsplit2, data_test_NYCtaxi_newsplit2, 402)
```
```{r}
# 2 Train:50%, Test:50%
set.seed(123)
split3 <- sort(sample(nrow(NYC_taxi_df), nrow(NYC_taxi_df)*0.5))
data_train_NYCtaxi_newsplit3 <- NYC_taxi_df[split3,]
data_test_NYCtaxi_newsplit3 <- NYC_taxi_df[-split3,]
k3 <- round(sqrt(nrow(data_train_NYCtaxi_newsplit3)))
k3
knn.predict3 <- function(data_train, data_test, k) 
{
    #extract 6th column from the dataset because it will be used as 'cl' argument in knn function.
    NYC_train_tip3 <- NYC_taxi_df[split3,6]
    #extract 6th column from the dataset to measure the MSE
    NYC_test_tip3 <- NYC_taxi_df[-split3,6]
    #run KNN function
    knn_reg_result <- knn.reg(data_train,data_test, NYC_train_tip3, k=k3)
    #MSE calculation 
    MSE3 <-mean((NYC_test_tip3 - knn_reg_result$pred)^2)
    cat("The MSE for k =", k, "is", MSE3, '\n')
    return(MSE3)
 }
knn_pred3 <-knn.predict3(data_train_NYCtaxi_newsplit3, data_test_NYCtaxi_newsplit3, 340)
```
We will evaluate the effect of percentage split, between training and test data, on the MSE(Mean Squared Error). We have used the square root of number of rows in training data as the value of k.

We have considered three percentage splits:

**1. Training Data:67%, Test Date:33%:** The MSE for this split is 0.002157202  for k value of 393. The MSE is less than the 80-20 split of the data. 

**2. Training Data:70%, Test Date:30%:** The MSE for this split is 0.00300849 for k value of 402. The MSE is greater than the 80-20 split of the data. But the MSE is less than the 67-33 split. 

**3. Training Data:50%, Test Date:50%:** The MSE for this split is 0.003604935 for k value of 340. The MSE is greater than the 80-20 split and than the 67-33 split as well as the 70-30 split. 

To conclude, The 67-33 percentage split is more efficient for this data. After that the 80-20 percentage split is better. The 50-50 split is least efficient of all. 



